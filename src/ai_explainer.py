"""
AI Model Architect - The "Brain"

This module provides AI-powered formula explanations and breakdown suggestions
with enterprise-grade security (data masking) and hybrid key management.

Key Features:
- Hybrid Strategy: Master Key (Standard) + BYOK (Pro)
- Data Masking: Never send raw financial values to LLM
- Azure OpenAI Compatible: Future-proof for Japanese enterprise
- Prompt Engineering: AI acts as "Senior FP&A Consultant"
- Persona Adjustment: AI tone adapts to model maturity level (Phase 7)
"""

from typing import Dict, List, Optional, Any
from abc import ABC, abstractmethod
import re
from dataclasses import dataclass

# ============================================================================
# AI Persona Prompts (Phase 7: Excel Rehab Maturity Model)
# ============================================================================

LEVEL_1_SYSTEM_PROMPT = """
„ÅÇ„Å™„Åü„ÅØ„ÄåÊàêÈï∑„Éë„Éº„Éà„Éä„Éº„Äç„Å®„Åó„Å¶„ÄÅ„É¶„Éº„Ç∂„Éº„ÅÆ„É¢„Éá„É´„ÇíÊ¨°„ÅÆ„É¨„Éô„É´„Å´Âºï„Åç‰∏ä„Åí„ÇãÂ∞ÇÈñÄÂÆ∂„Åß„Åô„ÄÇ

**„Ç≥„Éü„É•„Éã„Ç±„Éº„Ç∑„Éß„É≥ÂéüÂâá**:
‚úÖ Ê§úË®ºÁöÑ„Ç¢„Éó„É≠„Éº„ÉÅ: „Äå„Åì„Çå„ÅØ„Äá„Äá„Åß„Åô„Äç„Åß„ÅØ„Å™„Åè„Äå„Åì„Çå„ÅØ„Äá„Äá„ÅÆÂèØËÉΩÊÄß„Åå„ÅÇ„Çä„Åæ„Åô„Äç
‚úÖ „Éù„Ç∏„ÉÜ„Ç£„Éñ„Éï„É¨„Éº„É†: „Äå„Ç®„É©„ÉºÂõûÈÅø„Äç„Åß„ÅØ„Å™„Åè„ÄåÊñ∞„Åó„ÅÑËÉΩÂäõ„ÅÆÁç≤Âæó„Äç
‚úÖ Level 1„Éï„Ç©„Éº„Ç´„Çπ: ÂÆâÂÆöÊÄß„Å®ÂàÜËß£ÔºàDecompositionÔºâ„Å´ÈõÜ‰∏≠

**Âá∫Âäõ„Éï„Ç©„Éº„Éû„ÉÉ„ÉàÔºàÂé≥ÂÆàÔºâ**:
```
„ÄêÁô∫Ë¶ã„Äë
„Åì„ÅÆÂÄ§„ÅØ{diffusion}ÁÆáÊâÄ„Åß‰ΩøÁî®„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ
„Éë„Çø„Éº„É≥„Åã„ÇâË¶ã„Çã„Å®„ÄÅ„Åì„Çå„ÅØÂÄãÂà•„ÅÆÈ†ÖÁõÆ„Å®„ÅÑ„ÅÜ„Çà„Çä„ÄÅ„É¢„Éá„É´ÂÖ®‰Ωì„ÇíÂãï„Åã„ÅôÂâçÊèêÊù°‰ª∂„Åã„ÇÇ„Åó„Çå„Åæ„Åõ„Çì„ÄÇ

„ÄêÂèØËÉΩÊÄß„ÅÆÊ§úË®º„Äë
„ÇÇ„Åó„Åì„Çå„ÅåÁÇ∫Êõø„É¨„Éº„Éà„ÇÑÊàêÈï∑Áéá„ÅÆ„Çà„ÅÜ„Å™ÂâçÊèêÊù°‰ª∂„Å™„Çâ„ÄÅ‰ª•‰∏ã„ÅÆËÉΩÂäõ„ÅåËß£Êîæ„Åï„Çå„Åæ„ÅôÔºö
‚úì ÂÄ§„ÅÆÂàÜËß£: ÊßãÊàêË¶ÅÁ¥†„ÇíÊòéÁ¢∫Âåñ„Åó„ÄÅË®àÁÆóÊ†πÊã†„ÇíÂèØË¶ñÂåñ
‚úì ‰∏ÄÂÖÉÁÆ°ÁêÜ: {diffusion}ÁÆáÊâÄ„ÅÆÊõ¥Êñ∞„Çí1ÁÆáÊâÄ„Å´ÈõÜÁ¥Ñ
‚úì ÈÄèÊòéÊÄßÂêë‰∏ä: „ÉÅ„Éº„É†„É°„É≥„Éê„Éº„ÅåË®àÁÆó„Éï„É≠„Éº„ÇíÁêÜËß£„Åó„ÇÑ„Åô„Åè

„ÄêÂÆüË£Ö„Çπ„ÉÜ„ÉÉ„Éó: {prescription_mode}„Äë
1. [ÂÖ∑‰ΩìÁöÑ„Å™ÊâãÈ†Ü1]
2. [ÂÖ∑‰ΩìÁöÑ„Å™ÊâãÈ†Ü2]
3. [ÂÖ∑‰ΩìÁöÑ„Å™ÊâãÈ†Ü3]

üí° Ê¨°„ÅÆ„Çπ„ÉÜ„ÉÉ„Éó: „Åì„ÅÆÊîπÂñÑ„Å´„Çà„Çä„ÄÅ„É¢„Éá„É´„ÅÆÂÆâÂÆöÊÄß„ÅåÂêë‰∏ä„Åó„ÄÅLevel 2„ÅÆÂäπÁéáÂåñÊ©üËÉΩ„Åå‰Ωø„Åà„Çã„Çà„ÅÜ„Å´„Å™„Çä„Åæ„Åô„ÄÇ
```

**„Çπ„Éû„Éº„Éà„Éç„Éº„Éü„É≥„Ç∞ÔºàDiffusion > 10„ÅÆÂ†¥ÂêàÔºâ**:
„Åì„ÅÆÂÄ§„ÅØ{diffusion}ÁÆáÊâÄ„Åß‰ΩøÁî®„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ

üí≠ Ê§úË®º„Éù„Ç§„É≥„Éà: 
„ÇÇ„Åó„Äå{row_label}„Äç„ÅåÁâπÂÆö„ÅÆË°åÈ†ÖÁõÆ„Åß„ÅØ„Å™„Åè„ÄÅ„É¢„Éá„É´ÂÖ®‰Ωì„Å´ÂΩ±Èüø„Åô„ÇãÂâçÊèêÊù°‰ª∂ÔºàÁÇ∫Êõø„É¨„Éº„Éà„ÄÅÁ®éÁéá„Å™„Å©Ôºâ„Å™„Çâ„ÄÅ
„Çà„ÇäÊ±éÁî®ÁöÑ„Å™ÂêçÂâçÔºà‰æã: "USD_JPY_Rate", "Global_Tax_Rate"Ôºâ„ÅÆÊñπ„Åå„ÄÅÂ∞ÜÊù•„ÅÆÊã°ÂºµÊÄß„ÅåÈ´ò„Åæ„Çä„Åæ„Åô„ÄÇ

**Level 1„ÅÆÁõÆÊ®ô**: 
„Åæ„Åö„ÅØÂÄ§„ÇíÂàÜËß£„Åó„ÄÅË®àÁÆó„ÅÆÈÄèÊòéÊÄß„ÇíÁ¢∫‰øù„Åô„Çã„Åì„Å®„Åß„ÄÅ„É¢„Éá„É´„ÅÆ„ÄåÂÆâÂÆöÊÄß„Äç„ÇíÈ´ò„ÇÅ„Åæ„Åó„Çá„ÅÜ„ÄÇ
"""

LEVEL_2_SYSTEM_PROMPT = """
„ÅÇ„Å™„Åü„ÅØ„ÄåÂäπÁéáÂåñ„Éë„Éº„Éà„Éä„Éº„Äç„Å®„Åó„Å¶„ÄÅ„É¶„Éº„Ç∂„Éº„ÅÆ‰ΩúÊ•≠ÂäπÁéá„ÇíÊúÄÂ§ßÂåñ„Åô„ÇãÂ∞ÇÈñÄÂÆ∂„Åß„Åô„ÄÇ

**„Ç≥„Éü„É•„Éã„Ç±„Éº„Ç∑„Éß„É≥ÂéüÂâá**:
‚úÖ Ê§úË®ºÁöÑ„Ç¢„Éó„É≠„Éº„ÉÅ: „ÄåÂïèÈ°å„Åå„ÅÇ„Çã„Äç„Åß„ÅØ„Å™„Åè„ÄåÊîπÂñÑ„ÅÆÊ©ü‰ºö„Åå„ÅÇ„Çã„Äç
‚úÖ „Éù„Ç∏„ÉÜ„Ç£„Éñ„Éï„É¨„Éº„É†: „Äå„É™„Çπ„ÇØÂõûÈÅø„Äç„Åß„ÅØ„Å™„Åè„ÄåÂäπÁéá„ÅÆÂêë‰∏ä„Äç
‚úÖ Level 2„Éï„Ç©„Éº„Ç´„Çπ: ÂäπÁéáÊÄß„Å®‰∏ÄÂÖÉÁÆ°ÁêÜÔºàCentralizationÔºâ„Å´ÈõÜ‰∏≠

**Âá∫Âäõ„Éï„Ç©„Éº„Éû„ÉÉ„ÉàÔºàÂé≥ÂÆàÔºâ**:
```
„ÄêÁèæÁä∂ÂàÜÊûê„Äë
„Åì„ÅÆÂÄ§„ÅØ{occurrence_count}ÁÆáÊâÄ„Åß‰ΩøÁî®„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ
ÁèæÂú®„ÅÆÊßãÈÄ†„ÇíË¶ã„Çã„Å®„ÄÅÊõ¥Êñ∞‰ΩúÊ•≠„ÇÑÂ§âÊõ¥ÁÆ°ÁêÜ„Å´ÊôÇÈñì„Åå„Åã„Åã„Å£„Å¶„ÅÑ„ÇãÂèØËÉΩÊÄß„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ

„ÄêÂäπÁéáÂåñ„ÅÆÊ©ü‰ºö„Äë
„Åì„ÅÆÂÄ§„Çí‰∏ÄÂÖÉÁÆ°ÁêÜ„Åô„Çã„Å®„ÄÅ‰ª•‰∏ã„ÅÆËÉΩÂäõ„ÅåËß£Êîæ„Åï„Çå„Åæ„ÅôÔºö
‚úì ‰ΩúÊ•≠ÂäπÁéá: Êõ¥Êñ∞‰ΩúÊ•≠„Åå{occurrence_count}ÁÆáÊâÄ ‚Üí 1ÁÆáÊâÄ„Å´ÂâäÊ∏õ
‚úì Â§âÊõ¥ÁÆ°ÁêÜ: ‰øÆÊ≠£„ÅÆÂΩ±ÈüøÁØÑÂõ≤„ÅåÂç≥Â∫ß„Å´ÊääÊè°ÂèØËÉΩ
‚úì „ÉÅ„Éº„É†ÂçîÂÉç: ÂâçÊèêÊù°‰ª∂„ÅåÊòéÁ¢∫„Åß„ÄÅÂºïÁ∂ô„Åé„Åå„Çπ„É†„Éº„Ç∫„Å´

„ÄêÂÆüË£Ö„Çπ„ÉÜ„ÉÉ„Éó„Äë
1. [ÂÖ∑‰ΩìÁöÑ„Å™ÊâãÈ†Ü1]
2. [ÂÖ∑‰ΩìÁöÑ„Å™ÊâãÈ†Ü2]
3. [ÂÖ∑‰ΩìÁöÑ„Å™ÊâãÈ†Ü3]

üí° Ê¨°„ÅÆ„Çπ„ÉÜ„ÉÉ„Éó: „Åì„ÅÆÂäπÁéáÂåñ„Å´„Çà„Çä„ÄÅLevel 3„ÅÆÊà¶Áï•ÁöÑÊ©üËÉΩÔºà„Ç∑„Éä„É™„Ç™ÂàÜÊûê„Å™„Å©Ôºâ„Åå‰Ωø„Åà„Çã„Çà„ÅÜ„Å´„Å™„Çä„Åæ„Åô„ÄÇ
```

**„Çπ„Éû„Éº„Éà„Éç„Éº„Éü„É≥„Ç∞ÔºàDiffusion > 10„ÅÆÂ†¥ÂêàÔºâ**:
„Åì„ÅÆÂÄ§„ÅØ{diffusion}ÁÆáÊâÄ„Åß‰ΩøÁî®„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ

üí≠ Ê§úË®º„Éù„Ç§„É≥„Éà:
‰ΩøÁî®„Éë„Çø„Éº„É≥„Åã„ÇâË¶ã„Çã„Å®„ÄÅ„Åì„Çå„ÅØ„Äå{row_label}„Äç„Å®„ÅÑ„ÅÜÁâπÂÆöÈ†ÖÁõÆ„Åß„ÅØ„Å™„Åè„ÄÅ
„É¢„Éá„É´ÂÖ®‰Ωì„ÅÆÂâçÊèêÊù°‰ª∂ÔºàÁÇ∫Êõø„ÄÅÁ®éÁéá„ÄÅÊàêÈï∑Áéá„Å™„Å©Ôºâ„ÅÆÂèØËÉΩÊÄß„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ

„Åù„ÅÆÂ†¥Âêà„ÄÅ„Çà„ÇäÊ±éÁî®ÁöÑ„Å™ÂêçÂâçÔºà‰æã: "Assumption_FX_Rate", "Global_Growth_Rate"Ôºâ„Å´„Åô„Çã„Åì„Å®„Åß„ÄÅ
Â∞ÜÊù•„ÅÆÊã°Âºµ„ÇÑ‰ªñ„ÅÆ„É°„É≥„Éê„Éº„ÅÆÁêÜËß£„ÅåÂÆπÊòì„Å´„Å™„Çä„Åæ„Åô„ÄÇ

**Level 2„ÅÆÁõÆÊ®ô**:
ÂÄ§„Çí‰∏ÄÂÖÉÁÆ°ÁêÜ„Åô„Çã„Åì„Å®„Åß„ÄÅÊó•„ÄÖ„ÅÆ‰ΩúÊ•≠„ÄåÂäπÁéá„Äç„ÇíÈ´ò„ÇÅ„ÄÅÂ§âÊõ¥„Å´Âº∑„ÅÑ„É¢„Éá„É´„Çí‰Ωú„Çä„Åæ„Åó„Çá„ÅÜ„ÄÇ
"""

LEVEL_3_SYSTEM_PROMPT = """
„ÅÇ„Å™„Åü„ÅØ„ÄåÊà¶Áï•„Éë„Éº„Éà„Éä„Éº„Äç„Å®„Åó„Å¶„ÄÅ„É¶„Éº„Ç∂„Éº„ÅÆÊÑèÊÄùÊ±∫ÂÆö„ÇíÂä†ÈÄü„Åô„ÇãÂ∞ÇÈñÄÂÆ∂„Åß„Åô„ÄÇ

**„Ç≥„Éü„É•„Éã„Ç±„Éº„Ç∑„Éß„É≥ÂéüÂâá**:
‚úÖ Ê§úË®ºÁöÑ„Ç¢„Éó„É≠„Éº„ÉÅ: „Äå„Åì„Çå„Çí„Åô„Åπ„Åç„Äç„Åß„ÅØ„Å™„Åè„Äå„Åì„ÅÆÂèØËÉΩÊÄß„ÇíÊ§úË®é„Åß„Åç„Åæ„Åô„Äç
‚úÖ „Éù„Ç∏„ÉÜ„Ç£„Éñ„Éï„É¨„Éº„É†: „ÄåÂïèÈ°åËß£Ê±∫„Äç„Åß„ÅØ„Å™„Åè„ÄåÊñ∞„Åó„ÅÑËÉΩÂäõ„ÅÆÁç≤Âæó„Äç
‚úÖ Level 3„Éï„Ç©„Éº„Ç´„Çπ: Êà¶Áï•ÊÄß„Å®„Ç∑„Éä„É™„Ç™ÂàÜÊûêÔºàScenario PlanningÔºâ„Å´ÈõÜ‰∏≠

**Âá∫Âäõ„Éï„Ç©„Éº„Éû„ÉÉ„ÉàÔºàÂé≥ÂÆàÔºâ**:
```
„ÄêÊà¶Áï•ÁöÑÂèØËÉΩÊÄß„Äë
„Åì„ÅÆÂÄ§„ÅØ{occurrence_count}ÁÆáÊâÄ„Åß‰ΩøÁî®„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ
„É¢„Éá„É´„ÅÆÊàêÁÜüÂ∫¶„Åã„ÇâË¶ã„Çã„Å®„ÄÅÊà¶Áï•ÁöÑ„Å™ÂàÜÊûêÊ©üËÉΩ„ÇíËøΩÂä†„Åß„Åç„ÇãÊÆµÈöé„Å´Êù•„Å¶„ÅÑ„Åæ„Åô„ÄÇ

„ÄêËß£Êîæ„Åï„Çå„ÇãËÉΩÂäõ„Äë
„Åì„ÅÆÂÄ§„ÇíÊà¶Áï•ÁöÑ„Å´Ê¥ªÁî®„Åô„Çã„Å®„ÄÅ‰ª•‰∏ã„ÅÆÊñ∞„Åó„ÅÑËÉΩÂäõ„ÅåÁç≤Âæó„Åß„Åç„Åæ„ÅôÔºö
‚úì „Ç∑„Éä„É™„Ç™ÂàÜÊûê: Best/Base/Worst case„ÇíÁû¨ÊôÇ„Å´ÊØîËºÉ
‚úì ÊÑüÂ∫¶ÂàÜÊûê: „Å©„ÅÆÂâçÊèêÊù°‰ª∂„ÅåÊúÄ„ÇÇÂΩ±Èüø„Åô„Çã„ÅãÂç≥Â∫ß„Å´Âà§Êòé
‚úì What-ifÂàÜÊûê: ‰ºöË≠∞‰∏≠„Å´Êù°‰ª∂„ÇíÂ§â„Åà„Å™„Åå„Çâ„É™„Ç¢„É´„Çø„Ç§„É†„ÅßË©¶ÁÆó

„ÄêÂÆüË£Ö„Çπ„ÉÜ„ÉÉ„Éó„Äë
1. [ÂÖ∑‰ΩìÁöÑ„Å™ÊâãÈ†Ü1]
2. [ÂÖ∑‰ΩìÁöÑ„Å™ÊâãÈ†Ü2]
3. [ÂÖ∑‰ΩìÁöÑ„Å™ÊâãÈ†Ü3]

üí° Êà¶Áï•ÁöÑ‰æ°ÂÄ§: „Åì„ÅÆÊ©üËÉΩ„Å´„Çà„Çä„ÄÅÁµåÂñ∂‰ºöË≠∞„Åß„ÅÆ„Äå„ÇÇ„Åó„Äá„Äá„Å†„Å£„Åü„ÇâÔºü„Äç„Å®„ÅÑ„ÅÜË≥™Âïè„Å´„ÄÅ
„Åù„ÅÆÂ†¥„ÅßË§áÊï∞„ÅÆ„Ç∑„Éä„É™„Ç™„ÇíÊØîËºÉ„Åó„Å™„Åå„ÇâÂõûÁ≠î„Åß„Åç„Çã„Çà„ÅÜ„Å´„Å™„Çä„Åæ„Åô„ÄÇ
```

**„Çπ„Éû„Éº„Éà„Éç„Éº„Éü„É≥„Ç∞ÔºàDiffusion > 10„ÅÆÂ†¥ÂêàÔºâ**:
„Åì„ÅÆÂÄ§„ÅØ{diffusion}ÁÆáÊâÄ„Åß‰ΩøÁî®„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ

üí≠ Ê§úË®º„Éù„Ç§„É≥„Éà:
‰ΩøÁî®„Éë„Çø„Éº„É≥„Åã„ÇâË¶ã„Çã„Å®„ÄÅ„Åì„Çå„ÅØ„Äå{row_label}„Äç„Å®„ÅÑ„ÅÜÂÄãÂà•È†ÖÁõÆ„Åß„ÅØ„Å™„Åè„ÄÅ
„É¢„Éá„É´ÂÖ®‰Ωì„ÇíÂãï„Åã„ÅôÊà¶Áï•ÁöÑÂâçÊèêÊù°‰ª∂ÔºàÁÇ∫Êõø„ÄÅÊàêÈï∑Áéá„ÄÅÂ∏ÇÂ†¥„Ç∑„Çß„Ç¢„Å™„Å©Ôºâ„ÅÆÂèØËÉΩÊÄß„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ

„Åù„ÅÆÂ†¥Âêà„ÄÅÊà¶Áï•ÁöÑ„Å™ÂêçÂâçÔºà‰æã: "Strategic_Growth_Rate", "Market_Share_Target"Ôºâ„Å´„Åô„Çã„Åì„Å®„Åß„ÄÅ
„Ç∑„Éä„É™„Ç™ÂàÜÊûêÊôÇ„Å´ÂâçÊèêÊù°‰ª∂„Å®„Åó„Å¶Ë™çË≠ò„Åó„ÇÑ„Åô„Åè„Å™„Çä„Åæ„Åô„ÄÇ

**Level 3„ÅÆÁõÆÊ®ô**:
„Ç∑„Éä„É™„Ç™ÂàÜÊûêÊ©üËÉΩ„ÇíËøΩÂä†„Åô„Çã„Åì„Å®„Åß„ÄÅ„É¢„Éá„É´„Çí„ÄåÊà¶Áï•ÁöÑÊÑèÊÄùÊ±∫ÂÆö„ÉÑ„Éº„É´„Äç„Å´ÈÄ≤Âåñ„Åï„Åõ„Åæ„Åó„Çá„ÅÜ„ÄÇ
"""


@dataclass
class MaskedContext:
    """
    Context with masked numeric values for secure AI prompts.
    
    Attributes:
        formula_structure: Formula with numbers replaced by tokens
        cell_labels: Row and column labels for context
        dependencies: List of dependent cells (addresses only)
        value_mapping: Mapping of tokens to actual values (for internal use)
    """
    formula_structure: str
    cell_labels: Dict[str, str]
    dependencies: List[str]
    value_mapping: Dict[str, float]


class AIProvider(ABC):
    """
    Abstract base class for AI providers.
    
    Supports: OpenAI, Google Gemini, Azure OpenAI
    """
    
    def __init__(self, api_key: str, model: str = None):
        """
        Initialize AI provider.
        
        Args:
            api_key: API key for the provider
            model: Model name (provider-specific)
        """
        self.api_key = api_key
        self.model = model
    
    @abstractmethod
    def explain_formula(self, masked_context: MaskedContext) -> str:
        """
        Generate explanation for a formula.
        
        Args:
            masked_context: Context with masked values
            
        Returns:
            AI-generated explanation in Japanese
        """
        pass
    
    @abstractmethod
    def suggest_breakdown(self, masked_context: MaskedContext, 
                         driver_cells: List[str],
                         maturity_level: Optional[str] = None) -> str:
        """
        Suggest how to break down a hardcoded value.
        
        Args:
            masked_context: Context with masked values
            driver_cells: List of driver cells affected
            maturity_level: Maturity level for persona adjustment (LEVEL_1, LEVEL_2, LEVEL_3)
            
        Returns:
            AI-generated suggestion in Japanese
        """
        pass


class OpenAIProvider(AIProvider):
    """OpenAI GPT-4 provider"""
    
    def __init__(self, api_key: str, model: str = "gpt-4o"):
        super().__init__(api_key, model)
    
    def explain_formula(self, masked_context: MaskedContext) -> str:
        """Generate formula explanation using OpenAI"""
        try:
            from openai import OpenAI
            client = OpenAI(api_key=self.api_key)
            
            # Build prompt
            prompt = self._build_explanation_prompt(masked_context)
            
            # Call OpenAI API (new v1.0+ syntax)
            response = client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "„ÅÇ„Å™„Åü„ÅØÁµåÈ®ìË±äÂØå„Å™FP&A„Ç≥„É≥„Çµ„É´„Çø„É≥„Éà„Åß„Åô„ÄÇExcel„ÅÆÊï∞Âºè„ÇíÂàÜÊûê„Åó„ÄÅ„Éì„Ç∏„Éç„Çπ„ÅÆË¶≥ÁÇπ„Åã„ÇâË™¨Êòé„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=500
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            return f"AIË™¨Êòé„ÅÆÁîüÊàê„Å´Â§±Êïó„Åó„Åæ„Åó„Åü: {str(e)}"
    
    def suggest_breakdown(self, masked_context: MaskedContext, 
                         driver_cells: List[str],
                         maturity_level: Optional[str] = None) -> str:
        """Generate breakdown suggestion using OpenAI"""
        try:
            from openai import OpenAI
            client = OpenAI(api_key=self.api_key)
            
            # Select system prompt based on maturity level
            system_prompt = self._get_persona_prompt(maturity_level)
            
            # Build prompt
            prompt = self._build_breakdown_prompt(masked_context, driver_cells)
            
            # Call OpenAI API with persona-adjusted system prompt (new v1.0+ syntax)
            response = client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=500
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            return f"ÂàÜËß£ÊèêÊ°à„ÅÆÁîüÊàê„Å´Â§±Êïó„Åó„Åæ„Åó„Åü: {str(e)}"
    
    def _build_explanation_prompt(self, context: MaskedContext) -> str:
        """Build prompt for formula explanation"""
        labels = context.cell_labels
        row_label = labels.get('row_label', '‰∏çÊòé')
        col_label = labels.get('col_label', '‰∏çÊòé')
        
        prompt = f"""
‰ª•‰∏ã„ÅÆExcelÊï∞Âºè„ÇíÂàÜÊûê„Åó„Å¶„Åè„Å†„Åï„ÅÑÔºö

Êï∞ÂºèÊßãÈÄ†: {context.formula_structure}
Ë°å„É©„Éô„É´: {row_label}
Âàó„É©„Éô„É´: {col_label}
‰æùÂ≠ò„Çª„É´Êï∞: {len(context.dependencies)}

„Åì„ÅÆÊï∞Âºè„ÅÆÁõÆÁöÑ„Å®„ÄÅ„Éì„Ç∏„Éç„Çπ‰∏ä„ÅÆÊÑèÂë≥„ÇíÊó•Êú¨Ë™û„ÅßË™¨Êòé„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
„Åæ„Åü„ÄÅÊΩúÂú®ÁöÑ„Å™„É™„Çπ„ÇØ„Åå„ÅÇ„Çå„Å∞ÊåáÊëò„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
"""
        return prompt
    
    def _build_breakdown_prompt(self, context: MaskedContext, 
                                driver_cells: List[str]) -> str:
        """Build prompt for breakdown suggestion with global context and smart naming"""
        labels = context.cell_labels
        row_label = labels.get('row_label', '‰∏çÊòé')
        
        # Extract global context
        occurrence_count = labels.get('occurrence_count', '‰∏çÊòé')
        diffusion = labels.get('diffusion', occurrence_count)  # Use diffusion if available
        dominance = labels.get('dominance', len(driver_cells))
        value_type = labels.get('value_type', '‰∏çÊòé')
        actual_value = labels.get('actual_value', '‰∏çÊòé')
        prescription_mode = labels.get('prescription_mode', 'Centralization')
        
        # Smart naming guidance (if diffusion > 10)
        naming_guidance = ""
        try:
            if isinstance(diffusion, (int, float)) and diffusion > 10:
                naming_guidance = f"""

„ÄêÈáçË¶Å: „Çπ„Éû„Éº„Éà„Éç„Éº„Éü„É≥„Ç∞„Äë
„Åì„ÅÆÂÄ§„ÅØ{diffusion}ÁÆáÊâÄ„Åß‰ΩøÁî®„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åì„Çå„ÅØ„Äå{row_label}„Äç„Å®„ÅÑ„ÅÜÁâπÂÆöÈ†ÖÁõÆ„Åß„ÅØ„Å™„Åè„ÄÅ
„É¢„Éá„É´ÂÖ®‰Ωì„Å´ÂΩ±Èüø„Åô„Çã„Ç∞„É≠„Éº„Éê„É´ÂâçÊèêÊù°‰ª∂ÔºàÁÇ∫Êõø„É¨„Éº„Éà„ÄÅÁ®éÁéá„ÄÅÊàêÈï∑Áéá„Å™„Å©Ôºâ„ÅÆÂèØËÉΩÊÄß„ÅåÈ´ò„ÅÑ„Åß„Åô„ÄÇ

‚ùå ÊÇ™„ÅÑÂëΩÂêç‰æã: "{row_label}" ÔºàË™§Ëß£„ÇíÊãõ„ÅèÔºâ
‚úÖ ËâØ„ÅÑÂëΩÂêç‰æã: 
  - ÁÇ∫Êõø„ÅÆÂ†¥Âêà: "USD_JPY_Rate" „Åæ„Åü„ÅØ "FX_Rate_Assumption"
  - Á®éÁéá„ÅÆÂ†¥Âêà: "Corporate_Tax_Rate" „Åæ„Åü„ÅØ "Global_Tax_Rate"
  - ÊàêÈï∑Áéá„ÅÆÂ†¥Âêà: "Revenue_Growth_Rate" „Åæ„Åü„ÅØ "Market_Growth_Assumption"

ÂëΩÂêçÊôÇ„ÅØ„ÄÅ„Åì„ÅÆÂÄ§„ÅÆÊú¨Ë≥™ÁöÑ„Å™ÊÑèÂë≥ÔºàÁÇ∫Êõø„ÄÅÁ®éÁéá„ÄÅÊàêÈï∑Áéá„Å™„Å©Ôºâ„ÇíÂèçÊò†„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
"""
        except:
            pass
        
        prompt = f"""
„Äê„Ç∞„É≠„Éº„Éê„É´„Ç≥„É≥„ÉÜ„Ç≠„Çπ„Éà„Äë
- „Éè„Éº„Éâ„Ç≥„Éº„ÉâÂÄ§: {actual_value}
- ÂÄ§„ÅÆ„Çø„Ç§„Éó: {value_type}
- Âá∫ÁèæÂõûÊï∞ÔºàDiffusionÔºâ: {diffusion}ÁÆáÊâÄ
- ÂΩ±ÈüøÁØÑÂõ≤ÔºàDominanceÔºâ: {dominance}ÂÄã„ÅÆ„Çª„É´
- Ë°å„É©„Éô„É´: {row_label}
- Êé®Â•®„É¢„Éº„Éâ: {prescription_mode}
{naming_guidance}

„Äê„Çø„Çπ„ÇØ„Äë
„Åì„ÅÆÂÄ§„Çí‰∏ÄÂÖÉÁÆ°ÁêÜ„Åô„ÇãÊñπÊ≥ï„Çí„ÄÅ„Éì„Ç∏„Éç„Çπ‰æ°ÂÄ§„ÇíÂº∑Ë™ø„Åó„Å™„Åå„ÇâÊèêÊ°à„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

**ÂøÖÈ†àË¶ÅÁ¥†**:
1. „Éì„Ç∏„Éç„Çπ„É™„Çπ„ÇØ: „Å™„Åú„Åì„ÅÆ„Åæ„Åæ„Å†„Å®Âç±Èô∫„ÅãÔºà„Ç∑„Éä„É™„Ç™ÂàÜÊûê‰∏çÂèØ„ÄÅÁõ£ÊüªÂØæÂøúÂõ∞Èõ£„Å™„Å©Ôºâ
2. Êé®Â•®„ÇΩ„É™„É•„Éº„Ç∑„Éß„É≥: ÂÖ∑‰ΩìÁöÑ„Å™ÂÆüË£ÖÊâãÈ†ÜÔºà3-5„Çπ„ÉÜ„ÉÉ„ÉóÔºâ
3. „Éì„Ç∏„Éç„Çπ‰æ°ÂÄ§: ‰øÆÊ≠£Âæå„Å´Âæó„Çâ„Çå„Çã‰æ°ÂÄ§ÔºàÊÑèÊÄùÊ±∫ÂÆöÈÄüÂ∫¶„ÄÅ‰øùÂÆàÊÄß„ÄÅ‰ø°È†ºÊÄß„Å™„Å©Ôºâ
4. Pro Tip: ÂÆüÂãô„Åß„ÅÆÊ¥ªÁî®„Ç∑„Éº„É≥Ôºà‰ºöË≠∞„Åß„ÅÆÂç≥Á≠î„ÄÅÁõ£ÊüªÂØæÂøú„Å™„Å©Ôºâ

‚ùå Á¶ÅÊ≠¢: ExcelÊ©üËÉΩ„ÅÆË™¨ÊòéÔºà„ÄåÂêçÂâç‰ªò„ÅçÁØÑÂõ≤„Å®„ÅØ...„ÄçÔºâ
‚úÖ ÂøÖÈ†à: „Éì„Ç∏„Éç„Çπ‰æ°ÂÄ§„ÅÆÊèêÁ§∫Ôºà„Äå„Åì„Çå„Å´„Çà„ÇäÂèñÁ∑†ÂΩπ‰ºö„ÅßÂç≥Â∫ß„Å´„Ç∑„Éä„É™„Ç™ÊØîËºÉ„ÅåÂèØËÉΩ„ÄçÔºâ

**„Éà„Éº„É≥**: CFO„Ç¢„Éâ„Éê„Ç§„Ç∂„Éº„Å®„Åó„Å¶„ÄÅExcelÊ©üËÉΩ„Åß„ÅØ„Å™„Åè„ÄåÂÆâÂøÉÊÑü„Äç„Å®„ÄåÁ´∂‰∫âÂÑ™‰ΩçÊÄß„Äç„ÇíÂ£≤„Çã„ÄÇ
"""
        return prompt

    def _get_persona_prompt(self, maturity_level: Optional[str]) -> str:
        """
        Get AI persona prompt based on maturity level.
        
        Args:
            maturity_level: Maturity level (LEVEL_1, LEVEL_2, LEVEL_3)
            
        Returns:
            System prompt for the AI persona
        """
        if maturity_level == "LEVEL_1":
            return LEVEL_1_SYSTEM_PROMPT
        elif maturity_level == "LEVEL_2":
            return LEVEL_2_SYSTEM_PROMPT
        elif maturity_level == "LEVEL_3":
            return LEVEL_3_SYSTEM_PROMPT
        else:
            # Default: Level 1 Coach persona
            return LEVEL_1_SYSTEM_PROMPT


class GoogleProvider(AIProvider):
    """Google Gemini provider"""
    
    def __init__(self, api_key: str, model: str = "gemini-1.5-flash"):
        super().__init__(api_key, model)
    
    def explain_formula(self, masked_context: MaskedContext) -> str:
        """Generate formula explanation using Google Gemini"""
        try:
            import google.generativeai as genai
            genai.configure(api_key=self.api_key)
            
            model = genai.GenerativeModel(self.model)
            
            # Build prompt
            prompt = self._build_explanation_prompt(masked_context)
            
            # Call Gemini API
            response = model.generate_content(prompt)
            
            return response.text
            
        except Exception as e:
            return f"AIË™¨Êòé„ÅÆÁîüÊàê„Å´Â§±Êïó„Åó„Åæ„Åó„Åü: {str(e)}"
    
    def suggest_breakdown(self, masked_context: MaskedContext, 
                         driver_cells: List[str],
                         maturity_level: Optional[str] = None) -> str:
        """Generate breakdown suggestion using Google Gemini"""
        try:
            import google.generativeai as genai
            genai.configure(api_key=self.api_key)
            
            # Select system prompt based on maturity level
            system_prompt = self._get_persona_prompt(maturity_level)
            
            # Build prompt with persona
            user_prompt = self._build_breakdown_prompt(masked_context, driver_cells)
            full_prompt = f"{system_prompt}\n\n{user_prompt}"
            
            model = genai.GenerativeModel(self.model)
            
            # Call Gemini API
            response = model.generate_content(full_prompt)
            
            return response.text
            
        except Exception as e:
            return f"ÂàÜËß£ÊèêÊ°à„ÅÆÁîüÊàê„Å´Â§±Êïó„Åó„Åæ„Åó„Åü: {str(e)}"
    
    def _build_explanation_prompt(self, context: MaskedContext) -> str:
        """Build prompt for formula explanation"""
        labels = context.cell_labels
        row_label = labels.get('row_label', '‰∏çÊòé')
        col_label = labels.get('col_label', '‰∏çÊòé')
        
        prompt = f"""
„ÅÇ„Å™„Åü„ÅØÁµåÈ®ìË±äÂØå„Å™FP&A„Ç≥„É≥„Çµ„É´„Çø„É≥„Éà„Åß„Åô„ÄÇ

‰ª•‰∏ã„ÅÆExcelÊï∞Âºè„ÇíÂàÜÊûê„Åó„Å¶„Åè„Å†„Åï„ÅÑÔºö

Êï∞ÂºèÊßãÈÄ†: {context.formula_structure}
Ë°å„É©„Éô„É´: {row_label}
Âàó„É©„Éô„É´: {col_label}
‰æùÂ≠ò„Çª„É´Êï∞: {len(context.dependencies)}

„Åì„ÅÆÊï∞Âºè„ÅÆÁõÆÁöÑ„Å®„ÄÅ„Éì„Ç∏„Éç„Çπ‰∏ä„ÅÆÊÑèÂë≥„ÇíÊó•Êú¨Ë™û„ÅßË™¨Êòé„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
„Åæ„Åü„ÄÅÊΩúÂú®ÁöÑ„Å™„É™„Çπ„ÇØ„Åå„ÅÇ„Çå„Å∞ÊåáÊëò„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
"""
        return prompt
    
    def _build_breakdown_prompt(self, context: MaskedContext, 
                                driver_cells: List[str]) -> str:
        """Build prompt for breakdown suggestion with global context and smart naming"""
        labels = context.cell_labels
        row_label = labels.get('row_label', '‰∏çÊòé')
        
        # Extract global context
        occurrence_count = labels.get('occurrence_count', '‰∏çÊòé')
        diffusion = labels.get('diffusion', occurrence_count)  # Use diffusion if available
        dominance = labels.get('dominance', len(driver_cells))
        value_type = labels.get('value_type', '‰∏çÊòé')
        actual_value = labels.get('actual_value', '‰∏çÊòé')
        prescription_mode = labels.get('prescription_mode', 'Centralization')
        
        # Smart naming guidance (if diffusion > 10)
        naming_guidance = ""
        try:
            if isinstance(diffusion, (int, float)) and diffusion > 10:
                naming_guidance = f"""

„ÄêÈáçË¶Å: „Çπ„Éû„Éº„Éà„Éç„Éº„Éü„É≥„Ç∞„Äë
„Åì„ÅÆÂÄ§„ÅØ{diffusion}ÁÆáÊâÄ„Åß‰ΩøÁî®„Åï„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Åì„Çå„ÅØ„Äå{row_label}„Äç„Å®„ÅÑ„ÅÜÁâπÂÆöÈ†ÖÁõÆ„Åß„ÅØ„Å™„Åè„ÄÅ
„É¢„Éá„É´ÂÖ®‰Ωì„Å´ÂΩ±Èüø„Åô„Çã„Ç∞„É≠„Éº„Éê„É´ÂâçÊèêÊù°‰ª∂ÔºàÁÇ∫Êõø„É¨„Éº„Éà„ÄÅÁ®éÁéá„ÄÅÊàêÈï∑Áéá„Å™„Å©Ôºâ„ÅÆÂèØËÉΩÊÄß„ÅåÈ´ò„ÅÑ„Åß„Åô„ÄÇ

‚ùå ÊÇ™„ÅÑÂëΩÂêç‰æã: "{row_label}" ÔºàË™§Ëß£„ÇíÊãõ„ÅèÔºâ
‚úÖ ËâØ„ÅÑÂëΩÂêç‰æã: 
  - ÁÇ∫Êõø„ÅÆÂ†¥Âêà: "USD_JPY_Rate" „Åæ„Åü„ÅØ "FX_Rate_Assumption"
  - Á®éÁéá„ÅÆÂ†¥Âêà: "Corporate_Tax_Rate" „Åæ„Åü„ÅØ "Global_Tax_Rate"
  - ÊàêÈï∑Áéá„ÅÆÂ†¥Âêà: "Revenue_Growth_Rate" „Åæ„Åü„ÅØ "Market_Growth_Assumption"

ÂëΩÂêçÊôÇ„ÅØ„ÄÅ„Åì„ÅÆÂÄ§„ÅÆÊú¨Ë≥™ÁöÑ„Å™ÊÑèÂë≥ÔºàÁÇ∫Êõø„ÄÅÁ®éÁéá„ÄÅÊàêÈï∑Áéá„Å™„Å©Ôºâ„ÇíÂèçÊò†„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
"""
        except:
            pass
        
        prompt = f"""
„Äê„Ç∞„É≠„Éº„Éê„É´„Ç≥„É≥„ÉÜ„Ç≠„Çπ„Éà„Äë
- „Éè„Éº„Éâ„Ç≥„Éº„ÉâÂÄ§: {actual_value}
- ÂÄ§„ÅÆ„Çø„Ç§„Éó: {value_type}
- Âá∫ÁèæÂõûÊï∞ÔºàDiffusionÔºâ: {diffusion}ÁÆáÊâÄ
- ÂΩ±ÈüøÁØÑÂõ≤ÔºàDominanceÔºâ: {dominance}ÂÄã„ÅÆ„Çª„É´
- Ë°å„É©„Éô„É´: {row_label}
- Êé®Â•®„É¢„Éº„Éâ: {prescription_mode}
{naming_guidance}

„Äê„Çø„Çπ„ÇØ„Äë
„Åì„ÅÆÂÄ§„Çí‰∏ÄÂÖÉÁÆ°ÁêÜ„Åô„ÇãÊñπÊ≥ï„Çí„ÄÅ„Éì„Ç∏„Éç„Çπ‰æ°ÂÄ§„ÇíÂº∑Ë™ø„Åó„Å™„Åå„ÇâÊèêÊ°à„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

**ÂøÖÈ†àË¶ÅÁ¥†**:
1. „Éì„Ç∏„Éç„Çπ„É™„Çπ„ÇØ: „Å™„Åú„Åì„ÅÆ„Åæ„Åæ„Å†„Å®Âç±Èô∫„ÅãÔºà„Ç∑„Éä„É™„Ç™ÂàÜÊûê‰∏çÂèØ„ÄÅÁõ£ÊüªÂØæÂøúÂõ∞Èõ£„Å™„Å©Ôºâ
2. Êé®Â•®„ÇΩ„É™„É•„Éº„Ç∑„Éß„É≥: ÂÖ∑‰ΩìÁöÑ„Å™ÂÆüË£ÖÊâãÈ†ÜÔºà3-5„Çπ„ÉÜ„ÉÉ„ÉóÔºâ
3. „Éì„Ç∏„Éç„Çπ‰æ°ÂÄ§: ‰øÆÊ≠£Âæå„Å´Âæó„Çâ„Çå„Çã‰æ°ÂÄ§ÔºàÊÑèÊÄùÊ±∫ÂÆöÈÄüÂ∫¶„ÄÅ‰øùÂÆàÊÄß„ÄÅ‰ø°È†ºÊÄß„Å™„Å©Ôºâ
4. Pro Tip: ÂÆüÂãô„Åß„ÅÆÊ¥ªÁî®„Ç∑„Éº„É≥Ôºà‰ºöË≠∞„Åß„ÅÆÂç≥Á≠î„ÄÅÁõ£ÊüªÂØæÂøú„Å™„Å©Ôºâ

‚ùå Á¶ÅÊ≠¢: ExcelÊ©üËÉΩ„ÅÆË™¨ÊòéÔºà„ÄåÂêçÂâç‰ªò„ÅçÁØÑÂõ≤„Å®„ÅØ...„ÄçÔºâ
‚úÖ ÂøÖÈ†à: „Éì„Ç∏„Éç„Çπ‰æ°ÂÄ§„ÅÆÊèêÁ§∫Ôºà„Äå„Åì„Çå„Å´„Çà„ÇäÂèñÁ∑†ÂΩπ‰ºö„ÅßÂç≥Â∫ß„Å´„Ç∑„Éä„É™„Ç™ÊØîËºÉ„ÅåÂèØËÉΩ„ÄçÔºâ

**„Éà„Éº„É≥**: CFO„Ç¢„Éâ„Éê„Ç§„Ç∂„Éº„Å®„Åó„Å¶„ÄÅExcelÊ©üËÉΩ„Åß„ÅØ„Å™„Åè„ÄåÂÆâÂøÉÊÑü„Äç„Å®„ÄåÁ´∂‰∫âÂÑ™‰ΩçÊÄß„Äç„ÇíÂ£≤„Çã„ÄÇ
"""
        return prompt

    def _get_persona_prompt(self, maturity_level: Optional[str]) -> str:
        """
        Get AI persona prompt based on maturity level.
        
        Args:
            maturity_level: Maturity level (LEVEL_1, LEVEL_2, LEVEL_3)
            
        Returns:
            System prompt for the AI persona
        """
        if maturity_level == "LEVEL_1":
            return LEVEL_1_SYSTEM_PROMPT
        elif maturity_level == "LEVEL_2":
            return LEVEL_2_SYSTEM_PROMPT
        elif maturity_level == "LEVEL_3":
            return LEVEL_3_SYSTEM_PROMPT
        else:
            # Default: Level 1 Coach persona
            return LEVEL_1_SYSTEM_PROMPT


class AzureOpenAIProvider(AIProvider):
    """
    Azure OpenAI provider (future-proof for Japanese enterprise).
    
    Note: Requires additional configuration (endpoint, deployment_name)
    """
    
    def __init__(self, api_key: str, endpoint: str, deployment_name: str, 
                 model: str = "gpt-4"):
        super().__init__(api_key, model)
        self.endpoint = endpoint
        self.deployment_name = deployment_name
    
    def explain_formula(self, masked_context: MaskedContext) -> str:
        """Generate formula explanation using Azure OpenAI"""
        # Placeholder for Azure OpenAI implementation
        return "Azure OpenAIÁµ±Âêà„ÅØÊ∫ñÂÇô‰∏≠„Åß„Åô„ÄÇ"
    
    def suggest_breakdown(self, masked_context: MaskedContext, 
                         driver_cells: List[str]) -> str:
        """Generate breakdown suggestion using Azure OpenAI"""
        # Placeholder for Azure OpenAI implementation
        return "Azure OpenAIÁµ±Âêà„ÅØÊ∫ñÂÇô‰∏≠„Åß„Åô„ÄÇ"


class DataMasker:
    """
    Enterprise-grade data masking for AI prompts.
    
    CRITICAL: Never send raw financial values to LLM.
    Replace all numbers with tokens (<NUM_1>, <NUM_2>, etc.)
    """
    
    @staticmethod
    def mask_formula(formula: str) -> tuple[str, Dict[str, float]]:
        """
        Mask all numeric values in a formula.
        
        Args:
            formula: Original formula with numbers
            
        Returns:
            Tuple of (masked_formula, value_mapping)
            
        Example:
            Input:  "=B2*1.1+5000"
            Output: ("=B2*<NUM_1>+<NUM_2>", {"<NUM_1>": 1.1, "<NUM_2>": 5000})
        """
        if not formula:
            return "", {}
        
        # Find all numbers in the formula
        number_pattern = r'\b\d+\.?\d*\b'
        numbers = re.findall(number_pattern, formula)
        
        # Create mapping
        value_mapping = {}
        masked_formula = formula
        
        for i, num_str in enumerate(numbers, 1):
            token = f"<NUM_{i}>"
            value_mapping[token] = float(num_str)
            # Replace first occurrence
            masked_formula = masked_formula.replace(num_str, token, 1)
        
        return masked_formula, value_mapping
    
    @staticmethod
    def mask_value(value: Any) -> str:
        """
        Mask a single value.
        
        Args:
            value: Value to mask
            
        Returns:
            Masked token
        """
        if isinstance(value, (int, float)):
            return "<NUM_VAL>"
        return str(value)
    
    @staticmethod
    def create_masked_context(formula: str, cell_labels: Dict[str, str],
                             dependencies: List[str]) -> MaskedContext:
        """
        Create a masked context for AI prompts.
        
        Args:
            formula: Original formula
            cell_labels: Row and column labels
            dependencies: List of dependent cells
            
        Returns:
            MaskedContext with all values masked
        """
        masked_formula, value_mapping = DataMasker.mask_formula(formula)
        
        return MaskedContext(
            formula_structure=masked_formula,
            cell_labels=cell_labels,
            dependencies=dependencies,
            value_mapping=value_mapping
        )


class AIExplainer:
    """
    Main interface for AI explanations with Hybrid Strategy.
    
    Hybrid Strategy:
    - Standard Plan: Use master_key (if provided)
    - Pro Plan: Use user_key (if provided)
    - Fallback: Disable AI features
    """
    
    def __init__(self, master_key: Optional[str] = None):
        """
        Initialize AI Explainer.
        
        Args:
            master_key: Lumen's master API key (for Standard Plan)
        """
        self.master_key = master_key
        self.provider: Optional[AIProvider] = None
    
    def configure(self, provider_name: str, user_key: Optional[str] = None):
        """
        Configure AI provider with Hybrid Strategy.
        
        Args:
            provider_name: "OpenAI", "Google", or "Azure"
            user_key: User's custom API key (BYOK mode)
        """
        # Hybrid Strategy: user_key takes precedence
        api_key = user_key if user_key else self.master_key
        
        if not api_key:
            raise ValueError("No API key available. Provide user_key or master_key.")
        
        # Create provider
        if provider_name == "OpenAI":
            self.provider = OpenAIProvider(api_key)
        elif provider_name == "Google":
            self.provider = GoogleProvider(api_key)
        elif provider_name == "Azure":
            # Azure requires additional config
            raise NotImplementedError("Azure OpenAI requires endpoint configuration")
        else:
            raise ValueError(f"Unknown provider: {provider_name}")
    
    def explain_formula(self, formula: str, cell_labels: Dict[str, str],
                       dependencies: List[str], 
                       mask_data: bool = True) -> str:
        """
        Generate AI explanation for a formula.
        
        Args:
            formula: Formula to explain
            cell_labels: Row and column labels for context
            dependencies: List of dependent cells
            mask_data: Whether to mask numeric values (default: True)
            
        Returns:
            AI-generated explanation in Japanese
        """
        if not self.provider:
            return "AIÊ©üËÉΩ„ÅåË®≠ÂÆö„Åï„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇAPI„Ç≠„Éº„ÇíË®≠ÂÆö„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ"
        
        # Create masked context (ALWAYS mask for enterprise security)
        if mask_data:
            context = DataMasker.create_masked_context(formula, cell_labels, dependencies)
        else:
            # Even if mask_data=False, we still mask for security
            # This is a safety measure
            context = DataMasker.create_masked_context(formula, cell_labels, dependencies)
        
        # Call AI provider
        return self.provider.explain_formula(context)
    
    def suggest_breakdown(self, formula: str, cell_labels: Dict[str, str],
                         dependencies: List[str], driver_cells: List[str],
                         mask_data: bool = True,
                         maturity_level: Optional[str] = None) -> str:
        """
        Generate AI suggestion for breaking down a hardcoded value.
        
        Args:
            formula: Formula with hardcoded value
            cell_labels: Row and column labels for context
            dependencies: List of dependent cells
            driver_cells: List of driver cells affected
            mask_data: Whether to mask numeric values (default: True)
            maturity_level: Maturity level for persona adjustment (LEVEL_1, LEVEL_2, LEVEL_3)
            
        Returns:
            AI-generated suggestion in Japanese
        """
        if not self.provider:
            return "AIÊ©üËÉΩ„ÅåË®≠ÂÆö„Åï„Çå„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇAPI„Ç≠„Éº„ÇíË®≠ÂÆö„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ"
        
        # Create masked context (ALWAYS mask for enterprise security)
        if mask_data:
            context = DataMasker.create_masked_context(formula, cell_labels, dependencies)
        else:
            # Even if mask_data=False, we still mask for security
            context = DataMasker.create_masked_context(formula, cell_labels, dependencies)
        
        # Call AI provider with maturity level for persona adjustment
        return self.provider.suggest_breakdown(context, driver_cells, maturity_level)
